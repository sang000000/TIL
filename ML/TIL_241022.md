오늘은 딥러닝 6주차와 알고리즘 코드카타와 과제를 풀어보았다.

### **과적합 방지 기법**

---

### **1\. 과적화 방지 기법**

1.  정규화
    -   데이터를 일정한 범위로 조정하여, 모델의 학습을 안정화하고 성능을 향상하는 기법이다.
    -   배치 정규화: 각 미니 배치의 평균과 분산을 사용하여 정규화한다. 이는 학습 속도를 높이고, 과적합을 방지하는데 도움을 준다.
    -   레어 정규화: 각 레이어의 뉴런 출력을 정규화한다.

### **2.  드롭 아웃**

1.  -   학습 과정에서 무작위로 뉴런을 비활성화하여, 모델의 과적합을 방지하는 기법이다.
    -   학습시에만 적용이 되며, 평상시에는 모든 뉴런을 활성화 한다.

### **3\. 조기 종료 기법**

-   더 이상 데이터의 성능이 향상 되지 않을 떄 학습을 중단하여, 과적합을 방지한다.
-   조기 종료는 학습과정에서 검증 손실이 일정 에포크동안 감소하지 않으면 학습을 중단한다.

### **4\. 데이터 증강 기법**

-   원본 데이터를 변형하여 새로운 데이터를 생성함으로써, 데이터 셋을 확장하고 모델의 성능을 향상시키는 기법이다.
-   회전,이동,크기 조절, 색상 변환 등이 있다.

### **하이퍼 파라미터 튜닝**

---

### **1\. 개념**

-   모델 학습 과정에서 사용자가 설정해야 하는 값으로, 모델의 성능에 큰 영향을 미친다.

### **2.  학습률**

1.  -   모델의 가중치를 업데이트 할지 결정한다.
    -   너무 크면 학습이 불안정하고, 너무 작으면 학습이 느려진다.

### **3\. 배치 크기**

-   한 번의 업데이트에 사용되는 데이터 샘플의 수를 결정한다.
-   큰 배치 크기는 학습 속도를 높이지만, 메모리 사용량을 높인다.

### **4\. 에포크 수**

-   전체 데이터 셋을 몇번 반복하여 학습 할지를 결정한다.
-   너무 적으면 과소적합이 발생하고, 너무 많으면 과적합이 발생한다.
-   조기 종료 기법을 사용하여 적절한 에포크 수를 결정 할 수 있다.

### **5\. 모멘텀**

-   딥 러닝의 최적화 방법을 설정하는 것이다.
-   이전 기울기를 현재 기울기에 반영하여, 학습 속도를 높이고 진동을 줄인다.
-   빠른 수렴과 안전성을제공해준다는 게 장점이다.

### **6\. 가중치 초기화**

-   모델의 가중치를 초기화하는 방법을 결정한다.

### **7\. Grid Search**

-   하이퍼파라미터의 모든 조합을 시도하여 최적의 값을 찾는다.
-   계산 비용이 많이 들지만, 모든 조합을 탐색할 수 있다.

### **8\. Random Search**

-   하이퍼파라미터 공간에서 무작위로 값을 선택하여 최적의 값을 찾는다.
-   Grid Search보다 계산 비용이 적고, 더 넓은 하이퍼파라미터 공간을 탐색 할 수 있다.

### **9.Bayesian Optimization**

-   베이지안 최적화는 이전 평가 결과를 바탕으로, 다음 평가할 하이퍼파라미터를 선택한다.
-   계산 비용이 적고, 효율적으로 최적의 값을 찾을 수 있다.

### **교차 검증**

---

### **1\. 개념**

-   모델의 일반화 성능을 평가하기 위해 데이터를 여러번 나누어 학습과 검증을 반복하는 방법이다.
-   모델이 과적합되지 않고, 새로운 데이터에 대해 잘 일반화 되는지 평가하는데 유용하다.

### **2\. 필요성**

-   모델이 특정 데이터 셋에 과적합되지 않도록 도와준다.
-   모델의 일반화 성능을 더 정확하게 평가할 수 있다.
-   교차 검증은 데이터를 최대한 활용하여 모델을 평가할 수 있다.

### **Pytorch**

---

### **1\. 사용 기법**

-   torch.nm.moudle: 모든 신경망 모델의 기본 클래스이다.
-   torch.nn.MSELoss: 회귀 문제에 주로 사용된다.
-   torch.nn.CrossEntropyLoss: 분류 문제에 주로 사용된다.
-   torch.option.SGD: 확률적 경사 하강법 최적화 알고리즘이다.
-   torch.option.Adam: Adam 최적화 알고리즘이다.
-   torch.utils.data.Dataset: 사용자 정의 데이터 셋을 만들기 위한 기본 클래스이다.
-   torch.utils.data.DataLoader: 미니 배치 학습을 위한 데이터 로더이다.
-   torchvision.transforms: 이미지 데이터 변환을 위한 유틸리티이다.
-   torch.nn.conv2d: 2D 합성곱 레이어이다.
-   torch.nn. RNN: 기본 순환 신경망 레이어이다.
-   torch.nn.LSTM: LSTM 레이어이다.
-   torch.nn.GRU: GRU 레이어이다.
-   torch.nn.Transformer: 트랜스포머 모델이다.
-   torch.nn.TransformerEncoderLayer: 트랜스 포머 인코더 레이어이다.