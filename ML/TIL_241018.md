오늘은 딥러닝 3~4주차 강의 수강과 머신 러닝 복습을 하였고 알고리즘 코드카타 문제도 풀어보았다.

### **어텐션(Attention) 메커니즘**

---

### **1\. 개념**

-   시퀀스 데이터에서 중요한 부분에 더 많은 가중치를 할당하여 정보를 효율적으로 처리하는 기법이다.
-   주로 자연어 처리(NLP)와 시계열 데이터에서 사용되며, 기계 번역, 요약, 질의응답 시스템 등 다양한 분야에서 뛰어난 성능을 발휘한다.

### **2.동작 방식**

1.  개요
    -   입력 시퀀스의 각 요소에 대해 중요도를 계산하여 가중치를 부여한다.
    -   이를 통해 중요한 정보에 집중하고, 불필요한 정보를 무시할 수 있다.
2.  Attention 스코어 계산
    -   Attention 스코어는 Query와 Key 간의 유사도를 측정하여 중요도를 계산한다.
    -   이 유사도는 내적등을 사용하여 계산할 수 있다.
3.   Softmax를 통한 가중치 계산
    -   계산된 Attention 스코어는 Softmax 함수를 통해 확률 분포로 변환된다.
    -   이를 통해 가중치의 합이 1이 되도록 한다.
4.   Softmax를 통한 가중치 계산
    -   Softmax를 통해 얻어진 가중치를 Value에 곱하여 최종 Attention 출력을 계산한다.

### **3\. Self-Attention과 Multi-Head Attention**

1.  Self-Attention  
    -   Self-Attention은 시퀀스 내의 각 요소가 서로를 참조하는 메커니즘이다. 입력 시퀀스의 모든 요소가 Query, Key, Value로 사용된다.
    -   이를 통해 각 요소가 시퀀스 내 다른 요소들과의 관계를 학습할 수 있다.
    -   예를 들어, 문장 내에서 단어 간의 관계를 학습하여 번역이나 요약에 활용할 수 있다.
2.  Multi-Head Attention  
    -   Multi-Head Attention은 여러 개의 Self-Attention을 병렬로 수행하는 메커니즘이다.
    -   각 헤드는 서로 다른 부분의 정보를 학습하며, 이를 통해 모델이 다양한 관점에서 데이터를 처리할 수 있다.

### **자연어 처리 (NLP) 모델**

---

### **1\. 워드 임베딩과 시퀀스 모델링**

1.  워드 임베딩 기법
    -   워드 임베딩은 단어를 고정된 크기의 벡터로 변환하는 기법으로, 단어 간의 의미적 유사성을 반영한다.
    -   대표적인 워드 임베딩 기법으로는 Word2Vec과 GloVe가 있다.
2.  Word2Vec
    -   Word2Vec은 단어를 벡터로 변환하는 두 가지 모델을 제공한다.
    -   CBOW: 주변 단어(context)로 중심 단어(target)를 예측한다.
    -   Skip-gram: 중심 단어(target)로 주변 단어(context)를 예측한다.
3.  GloVe
    -   GloVe는 단어-단어 공기행렬을 사용하여 단어 벡터를 학습한다.
    -   전역적인 통계 정보를 활용하여 단어 간의 의미적 유사성을 반영한다.

### **2\. Transformer와 BERT**

1.  Transformer의 구조와 원리
    -   Transformer는 순차적인 데이터를 병렬로 처리할 수 있는 모델로, 자연어 처리에서 뛰어난 성능을 보인다.
    -   Transformer는 인코더-디코더(Encoder-Decoder) 구조로 구성된다.
2.  인코더
    -   입력 시퀀스를 처리하여 인코딩된 표현을 생성한다.
    -   각 인코더 층은 셀프 어텐션과 피드포워드 신경망으로 구성된다.
3.  디코더
    -   인코딩된 표현을 바탕으로 출력 시퀀스를 생성한다.
    -   각 디코더 층은 셀프 어텐션, 인코더-디코더 어텐션, 피드포워드 신경망으로 구성된다.
4.  어텐션 메커니즘
    -   어텐션 메커니즘은 입력 시퀀스의 각 위치에 가중치를 부여하여, 중요한 정보를 강조한다.
    -   셀프 어텐션은 입력 시퀀스 내의 단어 간의 관계를 학습한다.
5.  BERT
    -   BERT(Bidirectional Encoder Representations from Transformers)는 Transformer 인코더를 기반으로 한 사전 학습된 언어 모델이다.
    -   BERT는 양방향으로 문맥을 이해할 수 있어, 다양한 자연어 처리 작업에서 뛰어난 성능을 보인다.
6.  사전 학습
    -   BERT는 대규모 텍스트 코퍼스를 사용하여 사전 학습된다.
    -   마스킹 언어 모델과 다음 문장 예측 작업을 통해 학습된다.
7.  파인튜닝
    -   사전 학습된 BERT 모델을 특정 작업에 맞게 파인튜닝한다.
    -   텍스트 분류, 질의 응답, 텍스트 생성 등 다양한 자연어 처리 작업에 적용할 수 있다.

### **ResNet**

---

### **1. 개념**

-   ResNet(Residual Network)은 깊은 신경망을 학습하기 위해 개발된 모델로, 잔차 학습 개념을 도입하여 매우 깊은 네트워크에서도 효율적인 학습이 가능하도록 한다.
-   딥러닝 모델이 너무 깊어질 때 발생하는 기울기 소실 문제를 해결한다.
-   깊은 신경망은 더 많은 계층을 쌓아 복잡한 패턴을 학습할 수 있지만, 너무 깊어지면 학습이 어려워지는 문제가 있다.
-   주로 기울기 소실이나 기울기 폭발 같은 현상 때문에 발생한다.
-   이는 모델이 더 이상 깊어지지 못하고 성능이 저하되는 결과를 초래한다.
-   ResNet은 이러한 문제를 해결하기 위해 잔차 학습을 도입한다.
-   잔차 학습은 각 층의 출력이 바로 다음 층의 입력으로 전달되지 않고, 이전 층의 입력을 더해줌으로써 학습을 돕는다. 이를 통해 기울기 소실 문제를 완화할 수 있다.

### **2\. 특징**

-   잔차 학습을 통해 깊은 네트워크에서도 기울기 소실 문제를 해결한다.
-   입력을 출력에 더해줌으로써 신호가 더욱 쉽게 전달되어 학습이 원활하게 이루어진다.
-   간단한 블록 구조를 사용하여 네트워크를 쉽게 확장할 수 있다.
-   이미지 분류, 객체 검출 등 다양한 컴퓨터 비전 작업에서 높은 성능을 발휘한다.
-   깊은 네트워크에서도 안정적으로 학습할 수 있어, 복잡한 패턴을 잘 학습한다.

### **이미지 처리 모델**

---

### **1. 주요 CNN 아키텍쳐**

1.  ResNet (Residual Network)
    -   매우 깊은 신경망을 학습할 수 있도록 설계된 아키텍처이다.
    -   잔차 연결을 도입하여, 기울기 소실 문제를 해결한다.
    -   ResNet-50, ResNet-101, ResNet-152 등의 변형이 있다.
2.  VGG
    -   작은 3x3 필터를 사용하여 깊이를 증가시킨 아키텍처이다.
    -   VGG16과 VGG19가 대표적인 모델이다.
    -   단순하고 규칙적인 구조로 인해, 다양한 변형이 가능하다.
3.  Inception
    -   다양한 크기의 필터를 병렬로 적용하여, 여러 수준의 특징을 추출한다.
    -   Inception 모듈을 사용하여, 네트워크의 깊이와 너비를 동시에 확장한다.
    -   GoogLeNet(Inception v1), Inception v2, Inception v3 등이 있다.

### **2.YOLO(You Only Look Once)**

1.  개념  
    -   객체 탐지 모델로, 이미지에서 객체의 위치와 클래스를 동시에 예측한다.
    -   이미지 전체를 한 번에 처리하여, 빠르고 정확한 객체 탐지를 수행한다.
    -   이미지를 SxS 그리드로 나누고, 각 그리드 셀에서 객체의 존재 여부를 예측한다.
    -   각 그리드 셀은 B개의 바운딩 박스와 C개의 클래스 확률을 출력한다.
2.  동작원리  
    -   입력 이미지를 CNN을 통해 특징 맵으로 변환한다.
    -   특징 맵을 SxS 그리드로 나누고, 각 그리드 셀에서 바운딩 박스와 클래스 확률을 예측한다.
    -   예측된 바운딩 박스와 클래스 확률을 바탕으로, 객체의 위치와 클래스를 결정한다.

### **3\. 이미지 세그멘테이션**

1.  기법과 응용  
    -   이미지의 각 픽셀을 클래스 레이블로 분류하는 작업이다.
    -   주로 시맨틱 세그멘테이션과 인스턴스 세그멘테이션 두가지로 나뉜다
    -   시맨틱 세그멘테이션(Semantic Segmentation)은 이미지의 각 픽셀을 클래스 레이블로 분류한다.
    -   인스턴스 세그멘테이션(Instance Segmentation)은 시맨틱 세그멘테이션과 달리, 같은 클래스 내에서도 개별 객체를 구분한다.
2.  주요 모델  
    -   FCN (Fully Convolutional Network)는 모든 레이어를 합성곱 레이어로 구성하여, 픽셀 단위의 예측을 수행한다.
    -   U-Net은 U자형 구조를 가지며, 인코더-디코더 아키텍처를 사용하여 세그멘테이션을 수행한다.
    -   Mask R-CNN은 객체 탐지와 인스턴스 세그멘테이션을 동시에 수행하는 모델이다.