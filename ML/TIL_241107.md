오늘은 알고리즘 코드카타와 AI 모델 활용 복습과  5주차 강의 실습 코드를 실행해 보았다.

### **실습 코드**

---

### **1\. ChatGPT 웹 챗봇 서비스**

from fastapi import FastAPI, Request, Form

from fastapi.templating import Jinja2Templates

from fastapi.responses import HTMLResponse

from fastapi.staticfiles import StaticFiles

from openai import OpenAI

  

app \= FastAPI()

  

\# OpenAI API 클라이언트 설정

client \= OpenAI()

  

\# Jinja2 템플릿 설정

templates \= Jinja2Templates(directory\="app/templates")

  

\# 정적 파일 서빙

app.mount("/static", StaticFiles(directory\="app/static"), name\="static")

  

\# 초기 시스템 메시지 설정

system\_message \= {

    "role": "system",

    "content": "너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘"

}

  

\# 대화 내역을 저장할 리스트 초기화

messages \= \[system\_message\]

  

@app.get("/", response\_class\=HTMLResponse)

async def get\_chat\_page(request: Request):

    """채팅 페이지 렌더링"""

    conversation\_history \= \[msg for msg in messages if msg\["role"\] != "system"\]

    return templates.TemplateResponse("index.html", {"request": request, "conversation\_history": conversation\_history})

  

@app.post("/chat", response\_class\=HTMLResponse)

async def chat(request: Request, user\_input: str \= Form(...)):

    """사용자 메시지를 받아 OpenAI API 호출 및 응답 반환"""

    global messages

  

    \# 사용자의 메시지를 대화 내역에 추가

    messages.append({"role": "user", "content": user\_input})

  

    \# OpenAI API 호출

    completion \= client.chat.completions.create(

        model\="gpt-4o",

        messages\=messages

    )

  

    \# AI의 응답 가져오기

    assistant\_reply \= completion.choices\[0\].message.content

  

    \# AI의 응답을 대화 내역에 추가

    messages.append({"role": "assistant", "content": assistant\_reply})

  

    \# 화면에 표시할 대화 내역에서 system 메시지를 제외하고 전달

    conversation\_history \= \[msg for msg in messages if msg\["role"\] != "system"\]

  

    \# 결과를 HTML로 반환 (대화 내역과 함께)

    return templates.TemplateResponse("index.html", {

        "request": request,

        "conversation\_history": conversation\_history

    })

-   사용할 라이브러리를 가져온다.
-   FastAPI()를 사용하여 FastAPI 애플리케이션의 인스턴스를 생성하여 app에 저장한다.
-   OpenAI()를 사용하여 OpenAI API와 상호작용하기 위한 클라이언트 객체를 생성하여 client에 저장한다.
-   templates에는 Jinja2Templates()를 사용하여 Jinja2 템플릿을 사용할 디렉토리를 설정한다. Jinja 템플릿은 웹 애플리케이션에서 HTML 파일을 동적으로 생성하는 데 사용된다.
-   app.mount()를 사용하여 app/static 디렉토리의 정적 파일을 서빙한다.
-   system\_message에는 AI의 초기 시스템 메세지를 설정한다.
-   messages에는 리스트를 system\_message 값으로 하여 대화 내역을 저장할 리스트를 초기화한다.
-   @app.get()을 사용하여 루트 URL에 대한 get 요청을 처리하고 사용자가 채팅 페이제 접근할 떄 호출된다.
-   async def get\_chat\_page()에서는 대화 내역에서 시스템 메시지를 제외하고, Jinja2 템플릿을 사용하여 HTML 페이지를 렌더링한다.
-   @app.post()를 사용하여 경로에 대한 POST 요청을 처리한다. 사용자가 입력한 메시지를 받아 OpenAI API를 호출하고 응답을 반환한다.
-   그 다음에 message append({"role": "user", "content": user\_input}) 하여 사용자의 메시지를 대화 내역에 추가한다.
-   completion에는 chat.completions.create()를 사용하여 OpenAI API를 호출하여 대화 내역을 기반으로 AI의 응답을 생성하여 저장한다.
-   assistant\_reply에는 choices\[0\].message.content를 사용하여 Open AI API의 응답에서 AI의 메시지를 추출한다.
-   그 후 message에  append({"role": "assistant", "content": assistant\_reply})를 사용하여 AI의 응답을 대화 내역에 추가한다.
-   최종적으로 대화 내역을 HTML로 렌더링하여 사용자에게 반환한다.

### **2\. 영어-한국어 번역 및 음성 재생기**

import os

import requests

from dotenv import load\_dotenv

from PyQt5 import QtWidgets

from PyQt5.QtCore import QUrl

from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

from pydub import AudioSegment

from pydub.playback import play

import io

  

class TranslatorApp(QtWidgets.QWidget):

    def \_\_init\_\_(self):

        super().\_\_init\_\_()

        self.init\_ui()

  

        \# 번역 모델 로드

        model\_name \= "facebook/nllb-200-distilled-600M"

        self.tokenizer \= AutoTokenizer.from\_pretrained(model\_name)

        self.model \= AutoModelForSeq2SeqLM.from\_pretrained(model\_name)

  

        \# API 설정

        load\_dotenv()

        self.api\_key \= os.getenv("API\_KEY")

        self.url \= os.getenv("API\_URL")

  

        \# 음성 재생기

        self.player \= QMediaPlayer()

  

    def init\_ui(self):

        \# UI 구성

        self.text\_input \= QtWidgets.QLineEdit(self)

        self.text\_input.setPlaceholderText("번역할 텍스트 입력")

        self.translate\_button \= QtWidgets.QPushButton("번역 및 음성 생성", self)

        self.output\_label \= QtWidgets.QLabel(self)

        self.play\_button \= QtWidgets.QPushButton("음성 재생", self)

        self.play\_button.setEnabled(False)

  

        \# 레이아웃 설정

        layout \= QtWidgets.QVBoxLayout()

        layout.addWidget(self.text\_input)

        layout.addWidget(self.translate\_button)

        layout.addWidget(self.output\_label)

        layout.addWidget(self.play\_button)

        self.setLayout(layout)

  

        \# 버튼 클릭 시 이벤트 핸들러 연결

        self.translate\_button.clicked.connect(self.translate\_and\_generate\_audio)

        self.play\_button.clicked.connect(self.play\_audio)

  

        \# 윈도우 창 설정

        self.setWindowTitle("번역 및 음성 생성기")

        self.show()

  

    def translate\_and\_generate\_audio(self):

        text \= self.text\_input.text()

  

        \# 번역 수행

        inputs \= self.tokenizer(text, return\_tensors\="pt")

        generated\_tokens \= self.model.generate(inputs.input\_ids, forced\_bos\_token\_id\=self.tokenizer.lang\_code\_to\_id\["kor\_Hang"\])

        translated\_text \= self.tokenizer.decode(generated\_tokens\[0\], skip\_special\_tokens\=True)

  

        \# 음성 생성 요청

        data \= {

            "text": translated\_text,

            "model\_id": "eleven\_multilingual\_v2",

            "voice\_settings": {

                "stability": 0.5,

                "similarity\_boost": 1,

                "style": 0.5,

                "use\_speaker\_boost": True

            }

        }

        headers \= {

            "xi-api-key": self.api\_key,

            "Content-Type": "application/json"

        }

        response \= requests.post(self.url, json\=data, headers\=headers)

  

        if response.status\_code \== 200:

            output\_audio\_path \= "audio\_output/output\_audio.mp3"

            with open(output\_audio\_path, "wb") as f:

                f.write(response.content)

  

            self.output\_label.setText(f"번역 결과: {translated\_text}")

            self.play\_button.setEnabled(True)

        else:

            self.output\_label.setText("음성 생성 실패")

  

    def play\_audio(self):

        \# 음성 파일 재생

        audio\_path \= "audio\_output/output\_audio.mp3"

        if os.path.exists(audio\_path):

            \# Pydub을 통해 mp3 파일을 불러와서 재생

            audio \= AudioSegment.from\_mp3(audio\_path)

            play(audio)  \# Pydub의 play() 함수 사용

        else:

            self.output\_label.setText("오디오 파일을 찾을 수 없습니다.")

  

if \_\_name\_\_ \== '\_\_main\_\_':

    app \= QtWidgets.QApplication(\[\])

    translator \= TranslatorApp()

    app.exec\_()

-   사용할 라이브러리를 불러온다.
-   class TranslatorApp(QtWidgets.QWidget)를 사용하여 TranslatorApp  클래스에 QWidget을 상속받아 GUI 애플리케이션의 기본 구조를 설정한다.
-   클래스 안에서는 \_\_init\_\_ 메서드를 사용하여 클래스의 인스턴스가 생성될 때 호출한다. 여기서 init\_ui 메서드를 호출하여 UI를 초기화한다.
-   model\_name에는 facebook/nllb-200-distilled-600M 모델을 저장한다.
-   self.tokenizer에는 AutoTokenizer.from\_pretrained(model\_name)을 사용하여 해당 모델을 적절한 토크나이저를 자동으로 선택하고 생성하여 저장한다.
-   self.model에는 AutoModelForSeq2SeqLM.from\_pretrained(model\_name)를 사용하여 시퀀스 투 시퀀스 모델을 자동으로 로드하고 Seq2Seq 모델은 입력 시퀀스를 받아서 출력 시퀀스를 생성하는 모델로, 주로 번역, 요약, 질문 응답 등의 작업에 사용한다.
-   load\_dotenv()를 사용하여 .env 파일에 저장된 환경 변수를 로드한다.
-   self.api\_key와 self.url을 사용하여 API 키와 URL을 환경 변수에서 가져와 저장한다.
-   self.player에는 QMediaPlayer를 사용하여 음성을 재생할 준비를 한다.
-   def init\_ui(self)를 사용하여 애플리케이션의 UI를 구성하는 메서드를 만든다.
-   메서드 안에서는 self.text\_input는 사용자가 번역할 텍스트를 입력하는 텍스트 필드이고  
    self.translate\_button은 번역 및 음성 생성을 수행하는 버튼이고  
    self.output\_label은 번역 결과를 표시하는 레이블이고.  
    self.play\_button은 생성된 음성을 재생하는 버튼이다. 초기에는 비활성화되어 있다.
-   layout = QtWidgets.QVBoxLayout(),  
    layout.addWidget(self.text\_input),  
    layout.addWidget(self.translate\_button),  
    layout.addWidget(self.output\_label),  
    layout.addWidget(self.play\_button),  
    self.setLayout(layout)를 사용하여 수직 레이아웃을 생성하고 위젯들을 추가하여 UI를 구성한다.
-   self.translate\_button.clicked.connect(self.translate\_and\_generate\_audio),  
    self.play\_button.clicked.connect(self.play\_audio)를 사용하여 translate\_button 클릭 시 translate\_and\_generate\_audio 메서드를 호출하고, play\_button 클릭 시 play\_audio 메서드를 호출하도록 연결한다.
-   self.setWindowTitle("번역 및 음성 생성기")를 사용하여 윈도우 제목을 설정한다.
-   self.show()를 사용하여 UI를 화면에 표시한다.
-   def translate\_and\_generate\_audio(self):  
        text = self.text\_input.text()를 생성하여 사용자가 입력한 텍스트를 가져온다.
-   self.tokenizer(text, return\_tensors="pt")를 사용하여 입력 텍스트를 토크나이즈하고 모델에 전달하여 번역 결과를 생성해 inputs에 저장한다.
-   generated\_tokens = self.model.generate(inputs.input\_ids, self.tokenizer.lang\_code\_to\_id\["kor\_Hang"\]) translated\_text = self.tokenizer.decode(generated\_tokens\[0\], skip\_special\_tokens=True)을 사용하여 생성된 토큰을 다시 텍스트로 디코딩하여 forced\_bos\_token\_id에 저장한다.
-   data = {  
        "text": translated\_text,  
        "model\_id": "eleven\_multilingual\_v2",  
        "voice\_settings": {  
            "stability": 0.5,  
            "similarity\_boost": 1,  
            "style": 0.5,  
            "use\_speaker\_boost": True  
        }  
    }  
    headers = {  
        "xi-api-key": self.api\_key,  
        "Content-Type": "application/json"  
    }  
    response = requests.post(self.url, json=data, headers=headers) 이 코드들을 통해 번역된 텍스트를 음성으로 변환하기 위한 데이터와 헤더를 설정하고, POST 요청을 보낸다.
-   if response.status\_code == 200:  
        output\_audio\_path = "audio\_output/output\_audio.mp3"  
        with open(output\_audio\_path, "wb") as f:  
            f.write(response.content)  
      
        self.output\_label.setText(f"번역 결과: {translated\_text}")  
        self.play\_button.setEnabled(True)  
    else:  
        self.output\_label.setText("음성 생성 실패") 이 코드를 통해 요청이 성공하면 음성 파일을 저장하고, 번역 결과를 출력 레이블에 표시하며, 음성 재생 버튼을 활성화하고 실패 시에 에러 메시지를 표시한다.
-   def play\_audio(self):  
        audio\_path = "audio\_output/output\_audio.mp3"  
        if os.path.exists(audio\_path):  
            audio = AudioSegment.from\_mp3(audio\_path)  
            play(audio)  # Pydub의 play() 함수 사용  
        else:  
            self.output\_label.setText("오디오 파일을 찾을 수 없습니다.") 이 메서드를 생성하여 생성된 음성 파일을 재생한다. 파일이 존재하는지 확인한 후, Pydub을 이용해 MP3 파일을 재생한다.
-   if \_\_name\_\_ == '\_\_main\_\_':  
        app = QtWidgets.QApplication(\[\])  
        translator = TranslatorApp()  
        app.exec\_() 이 코드를 사용하여 애플리케이션을 실행한다.