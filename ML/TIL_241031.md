오늘은 AI모델 강의 1~2주차와 알고리즘 코드카타를 풀어보았다. 이제 과제도 일단 끝났으니 강의를 좀 더 열심히 들어봐야 할 것 같다.

### **AI 활용과 연구**

---

### **1\. 활용과 연구의 차이**

-   연구에서는 새로운알고리즘을 개발하거나, AI의 성능을 높이는 방법을 찾는다. 이는 수학적 이론과 복잡한 코드 작업이 필수적이고 점점 작업이 복잡해진다.
-   AI 활용은 이미 만들어진 AI 모델이나 API를 사용해 문제를 해결하는 것이다. 모델에 대해 깊게 들어가지는 않지만, AI의 능력을 실무에 적용하는데 중점을 둔다. 개발 시간이나 서비스 생성 시간을 고려해보면 압도적으로 AI활용쪽이 훨씬 빠르게 진행된다.

### **2.API 및 사전 학습 모델의 활용**

1.  API
    -   복잡한 AI 기능을 손쉽게 사용할 수 있도록 제공되는 인터페이스이다.
    -   프로그램끼리 통신을 하는 방법이다.
2.  사전 학습 모델
    -   많은 데이터로 미리 학습된 AI 모델이다. 활용하면 학습 과정을 생략하고, 곧바로 예측, 분류 작업에 사용이 가능하고 모델을 결합하여 사용하기에 편하고 안정성이 높다.

### **허깅 페이스**

---

### **1\. 개념**

-   자연어 처리(NLP)를 중심으로 다양한 AI 모델들을 제공하는 플랫폼이다.

### **2\. 특징**

-   BERT, GPT-3 같은 최신 NLP 모델들을 쉽게 사용할 수 있다.
-   수천개의 미리 학습 된 모델이 모여있기 떄문에 클릭 몇번으로 모델을 가져다 쓸 수 있다.
-   오픈 소스 커뮤니티를 중심으로 운영하기 때문에 전 세계 개발자들이 협력해 모델을 만들고 공유한다.

### **3\. 장점**

-   누구가 쉽게 사용할 수 있게 해주는 직관적인 인터페이스와 풍부한 튜토리얼을 제공한다.
-   다양한 분야와 언어에 걸쳐 수많은 모델을 제공한다.
-   무료로 사용이 가능하고, 커뮤니티가 함께 발전시켜 나가는 점이 큰 장점이다.
-   강력한 커뮤니티를 지원한다.

### **4\. 단점**

-   고성능 모델을 사용하려면 강력한 컴퓨팅 자원이 필요하다.
-   초보자에게는 처음 설정 과정이 조금 까다로울 수 있다.
-   NLP 외의 다른 AI 분야에서는 상대적으로 모델의 수가 적다.

### **Github와 오픈 소스**

---

### **1\. Github**

-   코드 저장소이자 협업 플랫폼이다.
-   전 세계 개발자들이 모여 코드와 아이디어를 공유하고 함께 프로젝트를 진행하는 공간이다.

### **2.오픈 소스**

-   소스 코드가 공개된 소프트웨어를 말한다.
-   누구나 이 코드를 보고, 수정하고, 배포할 수 있다.
-   라이센스의 종류에 대해선 상세히 살펴 보는게 좋다.

### **API**

---

### **1\. 개념**

-   API는 Application Programing Interface의 줄임말로, 프로그램 간에 데이터를 주고 받을 수 있게 해주는 인터페이스이다.
-   두 개 이상의 소프트웨어 구성 요소가 서로 통신하고 기능을 공유할 수 있도록 규칙과 프로토콜을 제공한다.

### **2\. 동작 방법**

-   API 서비스를 제공해주는 서버와 이걸 이용하는 클라이언트 간에 요청과 응답을 주고 받는 방식으로 작동한다.

### **3\. 장점**

-   복잡한 AI 기술을 직접 구현할 필요가 없으며, 간단한 API 호출로 다양한 기능이 사용 가능하다.
-   사용이 쉬워서 빠르게 프로토 타입을 만들고, 새로운 기능을 구현할 수 있다.
-   다양한 API를 결합해 복합적인 기능을 구현할 수 있다.

### **4\. 단점**

-   API 사용에 따라 비용이 발생할 수 있어, 비용이 커실 수 있다.
-   제공된 기능만 사용이 가능하며, 커스터 마이징에는 제한이 있을 수 있다.
-   특정 API에 의존하게 되면, 해당 서비스가 중단되거나 변경될 때 문제가 발생할 수 있다.

### **5\. 팁**

-    API를 사용할 때는 항상 공식 문저를 꼼꼼히 읽오야 문제 없이 활용이 가능하다.
-   발급 받은 키는 신중하게 관리해야 보안 문제가 발생하지 않고, 환경 변수를 통해 관리하는 게 좋다.
-   대부분은 무료 할당량이 있기 때문에 초기에는 비용없이 충분히 테스트가 가능하다.

### **6\. 관련 용어**

-   EndPoint: API가 서비스를 제공하는 주소이다.
-   Request: 클라이언트가 서버에 보내는 메시지이다.
-   Response: 서버가 클라이언트의 요청에 대해 반환하는 데이터이다.

### **PyTorch와 Transformer**

---

### **1\. 개념**

1.  Pytorch
    -   Facebook AI Research에서 개발한 딥러닝 프레임 워크로, 유연하고 사용하기 쉬운 덕분에 인기가 많다.
    -   이 프레임 워크를 사용하면 딥러닝 모델을 쉽게 구축하고 실험라 수 있다.
2.  Transformer
    -   자연어 처리(NLP)에서 뛰어난 성능을 보이는 모델로 Self-Attention 메커니즘을 활용해 텍스트의 문맥을 파악하고, 병렬 처리에 강한 구조를 가지고 있다.

### **2\. PyTorch로 Transformer 모델 구현시 문제점**

1.  데이터 및 컴퓨팅 자원의 한계:
    -   Transformer 모델은 대량의 데이터와 자원을 요구하며, 일반적으로 수십 기가바이트의 GPU 메모리가 필요하다. 학습에 몇 주가 걸릴 수 있다.
2.  모델 크기와 메모리 사용량:  
    -   모델이 커질수록 메모리 사용량이 기하급수적으로 증가하여, 개인의 일반적인 컴퓨터나 단일 GPU로 학습하기 어려운 상황이 발생한다.
3.  구현의 어려움:
    -   Transformer의 구조가 복잡해 처음부터 구현하기 위해서는 다양한 개념(예: Self-Attention, Multi-Head Attention 등)에 대한 깊은 이해가 필요하다.
4.  하이퍼파라미터 튜닝:
    -   적절한 학습률, 모델 크기, 레이어 수 등의 하이퍼파라미터를 조정하는 과정에서 많은 시행착오가 필요하며, 최적의 파라미터를 찾기 위해서는 시간이 소요된다.
5.  맞춤화의 어려움:
    -   사전 학습된 모델은 특정 데이터나 작업에 대해 최적화되어 있으므로, 다른 작업에 맞추기 위해서는 추가적인 미세 조정이 필요하다.
6.  비용 문제:
    -   미세 조정이나 추가 학습을 위해서는 고성능 장비나 클라우드 서비스를 이용해야 하며, 이는 상당한 비용을 초래할 수 있다.

### **3\. 극복 방법**

-   Google Colab이나 AWS와 같은 클라우드 기반 GPU 서비스를 사용하면, 개인 컴퓨터의 하드웨어 한계를 넘어 강력한 GPU 자원을 활용할 수 있다.
-   이러한 서비스는 무료 또는 저렴한 비용으로 제공되며, 고성능의 컴퓨팅 파워를 통해 대형 모델을 보다 쉽게 학습할 수 있다.
-   Hugging Face의 Transformers 라이브러리나 PyTorch Hub에서 제공하는 사전 학습된 모델을 활용하면, 복잡한 구조를 처음부터 구현할 필요가 없다.
-   사전 학습된 모델을 사용하여 필요한 부분만 미세 조정(Fine-Tuning)하면, 특정 작업에 맞는 모델을 쉽게 만들 수 있다.
-   DistilBERT나 TinyBERT와 같은 경량화된 모델은 대형 모델의 성능을 일정 수준 유지하면서도 자원 소모를 줄일 수 있다.
-   이러한 모델들은 메모리 사용량이 적고, 학습 속도가 빠르기 때문에, 자원이 제한된 환경에서도 효과적으로 사용할 수 있는 좋은 대안이다.