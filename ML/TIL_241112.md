오늘은 알고리즘 코드 카타와 LLM & RAG를 활용한 AI 서비스 만들기 5주차 강의를 수강하였다.

### **보안 문제**

---

### **1\. LLM을 사용할 때의 데이터 보안 문제**

-   대화를 통해 개인 정보를 접할 수 있고 이런 정보가 저장되거나 제 3자에게 공유될 경우 큰 문제가 될 수 있다.
-   LLM이 처리한 데이터가 어디에 저장되는지, 어떻게 전송되는지를 확인해야 하고 암호화된 전송 방식을 사용해 데이터를 보호해야 한다.
-   LLM은 학습에 사용 된 데이터에 의존해 답변을 생성하고 만약 학습 데이터에 민감한 정보가 포함된다면, 해당 정보가 예기치 않게 모델의 출력으로 등장할 가능성도 있다.

### **2\. 보완을 강화하는 방법**

1.  입력된 데이터를 처리하기 전에 민감한 정보를 자동으로 걸러내는 필터링 시스템을 구축한다.
2.  데이터는 저장 및 전송 중에 암호화되어야 한다. 특히 SSL/TLS와 같은 안전한 전송 프로토콜을 사용해야 한다.
3.  필요 이상으로 데이터를 저장하지 말고, 필요한 경우에도 데이터 보존 주기를 설정해 자동 삭제 하도록한다.
4.  LLM을 사용할 수 있는 사람의 권한을 제한하고, 모델이 민감한 데이터에 접근하지 않도록 제한한다.

### **API**

---

### **1\. 개념**

-   클라이언트(요청하는 쪽)가 서버(응답하는 쪽)에게 데이터를 요청하면, 서버는 해당 데이터를 처리하여 클라이언트에게 반환한다.
-   대부분이 API는 HTTP나 HTTPS를 통해 요청과 응답이 이루어진다.
-   RESTful API는 가장 흔히 사용되는 API 설계 방식으로 엔드 포인트와 HTTP 메소드를 사용해 데이터를 주고 받는다.

### **2\. API 사용의 주요 장점**

-   필요할 때마다 요청을 보내어 결과를 받을 수 있어, 실시간으로 다양한 앱에 적용할 수 있다.
-   다양한 서비스나 플랫폼에 쉽게 통합할 수 있어, 여러 사용자가 동시에 사용할 수 있는 확장성을 가진다.
-   LLM API 제공사가 모델을 업데이트 하면, 별다른 수정없이 최신 기능을 바로 사용할 수 있다.
-   API 호출에 따라 비용이 청구되므로, 대규모 서버를 유지할 필요없이 필요한 만큼만 사용 가능하다.

### **벡터 DB와 LangChain 활용하기**

---

### **1\. 벡터 DB와 LangChain 활용하기**

-   벡터 DB는 이미지 혹은 텍스트와 같이 숫자가 아닌 데이터를 숫자로 바꾼 다음 이를 저장하고 유사한 데이터끼리 찾을 수 있는 기능을 제공하는 데이터베이스이다.
-   LangChain은 LLM과 DB를 연결해주는 프레임워크로, 데이터 흐름을 관리하고 API 호출을 더 간편하게 만들어 준다.

### **2\. LLM + 벡터 DB + LangChain 구축 플로우**

1.  먼저 LLM이나 임베딩 벡터를 통해 텍스트 데이터를 벡터(임베딩)로 변환한다. 이는 특정 문서나 문장 같은 것들이 있을 때, 이걸 숫자 나열인 벡터로 바꿔주는 것이다.
2.  변환 된 임베딩을 벡터 DB에 저장한다.
3.  사용자가 질문을 하면, 질문도 벡터로 변환하고 벡터 DB에서 유사한 임베딩을 찾는다.
4.  찾은 유사한 데이터와 함께 LLM을 통해 최종 답변을 생성한다.
5.  이 과정을 통해 LLM이 학습 못한 데이터도 답변을 만드는데 활용될 수 있게 된다.

### **Vector DB**

---

### **1\. 개념**

-   데이터를 벡터 형식으로 저장하고, 그 벡터들을 효율적으로 검색할 수 있는 데이터 베이스이다.
-   Vector DB는 유사한 벡터 간의 검색을 지원한다.

### **2\. 벡터(임베딩)의 역할**

-   텍스트나 이미지등의 비정형 데이터를 벡터화(임베딩)해서 저장한다.
-   이 벡터는 의미나 특징을 수치로 표현한 것이며, 이를 바탕으로 유사도를 계산해 관련성이 높은 항목을 찾는다.

### **임베딩(Embedding)**

---

### **1\. 개념**

-   텍스트, 이미지 등의 데이터를 고차원 공간에서 벡터(숫자 배열)로 변환하는 작업이다.
-   LLM이 문장을 이해하기 위해서는 단어와 문장을 벡터로 변환해야, 컴퓨터가 의미적 유사정을 기반으로 데이터를 처리 할 수 있다.
-   임베딩은 단어 간의 의미적 관계를 벡터 공간에 투영한다.

### **RAG(Retrieval - Augmented Generation)**

---

### **1\. 개념**

-   LLM과 검색 시스템을 결합한 개념이다.
-   RAG는 기존의 LLM만으로 해결할 수 없는 문제를, 외부 정보 검색을 통해 보완한다.

### **2\. 동작원리**

1.  사용자가 질문하면, 벡터 DB에서 질문과 유사한 문서나 데이터를 검색한다.
2.  이 때 임베딩 모델을 사용해 질문을 벡터로 변환하고, 벡터 간의 유사도를 계산해 관련 데이터를 찾아낸다.
3.  검색된 문서를 LLM에 전달하고, 이를 바탕으로 자연스러운 답변을 생성한다.
4.  검색된 문서를 참조해 최신 정보를 포함한 정확한 답변을 제공한다.

### **3\. 장점**

-   LLM이 학습한 데이터 외의 최신 문서를 검색해 정보의 정확도를 높일 수 있다.
-   LLM이 모르는 정보도 외부 검색을 통해 답변할 수 있어 지식의 확장성이 뒤어난다.
-   학습 데이터에만 의존하지 않고, 외부 데이터 베이스에서 실시간 정보를 제공 받아 더욱 풍부한 답변을 할 수 있다.

### **텍스트 처리**

---

### **1\. 중요한 이유**

-   데이터의 품질을 높이고 모델의 성능을 향상시키기 위한 필수 작업이다.
-   자연어는 매우 복잡하고 다양하기 때문에, LLM이 텍스트를 정확하게 이해하고 처리하기 위해서는 데이터가 구조화되고 정제될 필요가 있다.
-   잘못된 텍스트 처리 과정은 모델이 혼동하거나 잘못된 추론을 하게 할 수 있다.

### **2\. 목표**

-   텍스트 내 불필요한 정보나 오류를 제거해 정확한 분석을 할 수 있도록 한다.
-   문장의 구조나 형태를 일관되게 유지하여 모델이 더 쉽게 패턴을 학습하게 돕는다.
-   불필요한 단어를 제거하고 중요한 정보만 남겨, 모델이 더 빠르게 계산할 수 있도록 해준다.

### **3\. 텍스트 처리 기법**

1.  토큰화(Tokenization)
    -   토큰화는 텍스트를 단어 또는 서브워드 단위로 나눈다.
    -   이 과정은 텍스트를 숫자로 변환하기 전의 가장 중요한 단계이다.
    -   단어 단위 토큰화는 텍스트를 공백이나 구둣점을 기준으로 단어 단위로 나누는 기본 방법으로 상대적으로 간단하고 빠르다.
    -   단어 단위 토큰화는 대부분에 자연어 처리에 사용이 가능하지만, 한국어와 같은 언어는 단어의 경계가 공백이나 구둣점을 기준으로 해도 명확하지 않다.
    -   서브워드 토큰화는 단어를 더 작은 단위로 분리해 새로운 단어를 처리할 수 있도록 하는 방법으로, 언어의 새로운 단어나 희귀 단어를 처리하는데 유용하다,
    -   서브워드 토큰화는 분할 과정이 복잡하고 일부 단어는 분해 시 의미가 왜곡될 수 있다.
    -   Sentence Level 토큰화는 텍스트를 문장 단위로 분할하여 각 문장을 개별적으로 분석하게 한다. 이는 문맥에 요약이 필요할 때 유용하며, 요약이나 문장 경계가 모호하면 복잡도가 증가하고 긴문장에서는 정확한 경계 탐지가 어렵다.
2.   정규화(Normalization)
    -   텍스트를 표준화된 형식으로 변환하는 작업이다.
    -   텍스트에 포함된 대소문자, 구둣점, 특수 문자 등을 일관되게 변환하여, 모델이 불필요한 변동에 혼란을 겪지 않도록 한다.
    -   어간 추출이나 표지어를 추출해서 단어의 변형된 형태를 통일된 기본 형태로 사용되게 할 수 있다.
3.  불용어 제거(Stopword Removal)
    -   자주 등장하지만 정보가 없는 단어를 말한다.
    -   문맥에 큰 영향을 미치지 않기 때문에, 이를 제거하면 모델이 중요한 단어만 집중할 수 있다.
    -   잘 못 제거할 경우 의미가 왜곡될 수 있다.

### **임베딩 기법**

---

### **1\. Bag of Words(BoW)**

-   단어의 빈도만을 기반으로 텍스트를 벡터화하는 가장 단순한 방법이다.
-   단어의 순서나 문맥을 고려하지 않기 때문에 의미 파악에 한계가 있지만, 간단한 문서 분류나 텍스트 분석에 유용하다.

### **2.TF-IDF(Term Frequency - Inverse Document Frequency)**

-   TF - IDF는 단순한 단어 빈도 외에도 단어의 중요도를 반영한 임베딩 기법이다.
-   특정 단어가 문서 내에서 자주 등장하지만 전체 문서에서 드물게 등장한다면, 그 단어는 해당 문서에서 중요한 단어로 간주한다.
-   문서간의 중요한 단어를 구별하고 희소성 문제를 일부 해소할 수 있다.
-   문맥을 반영하지 않아 의미적인 분석에는 약하고 어휘에 따라 벡터를 만들기 때문에 어휘수가 많으면 고착원 벡터가 된다.

### **3\. Word2Vec, GloVe**

-   단어 간의 의미적 유사성을 반영하는 임베딩 기법이다.
-   단어를 고차원 벡터로 변환하여, 단어 간의 관계를 학습한다.
-   Word2Vec은 주위 단어들에 기반해 단어의 의미를 학습한다.
-   GloVE는 전체 문맥을기반으로 단어간의 공통 패턴을 학습한다.
-   Word2Vec은 단어를 저차원 밀집 벡터로 표현하여 단어 간의 유사성을 반영하여 의미적으로 비슷한 단어들이 비슷한 벡터로 표현되고 메모리 효율이 좋고 개선 속도가 빠르다.
-   WOkrd2Vec은 학습이 한 번 되면 고정된 단어 벡터로 인해 새로운 단어를 추가할 수 없고 단어의 문맥을 한정된 창 내에서만 교려해서 문장 전체 맥락을 파악하지 못 한다.
-   GloVe는 전체 문맥 정보로 학습하기 떄문에, 단어 간의 관계를 반영하는 동시에, 단어가 등장하는 전체 문장을 고려한다.
-   GloVe는 대규모의 코퍼스가 필요하므로 작은 데이터 셋에서 성능이 낮을 수 있고 임베딩이 고정되서 학습 후에는 새 단어 추가를 할 수 없다.

### **4\. Transformer**

-   문장 전체 맥락을 고려하기 때문에 문장 내의 위치에 따라 단어의 의미를 다르게 표현할 수 있다.
-   개선 비용이 크고 메모리와 저장 공간을 많이 차지한다.
-   모델들은 문장의 문맥을 고려하여 더 깊이 있는 의미를 반영한 임베딩을 생성한다.
-   문장 단위로 텍스트를 벡터화할 수 있어 문장 간의 유사도를 정확하게 파악한다.
-   BERT는 양방향으로 문맥을 고려한 임베딩을 생성한다.
-   GPT는 자동 완성 및 생성에 강점을 둔 임베딩을 생성한다.

### **LangChain**

---

### **1\. 개념**

-   언어 모델을 중심으로 다양한 데이터 소스와 툴을 연결하여 체인 기반 애플리케이션을 구축할 수 있는 Python 기반 프레임워크이다.
-   하나의 언어 모델 응답만 받는 대신, 여러 단계로 구성된 체인 구조를 통해 다양한 연산과 데이터 처리, 멀티스텝 분석이 가능하다.

### **2\. 장점**

-   언어 모델과 다양한 컴포넌트를 쉽게 연결할 수 있다.
-   모델의 응답을 다른 컴포넌트로 보내거나, 여러 단계에 걸친 데이터 처리가 가능하다.
-   프롬프트 템플릿, 출력 파서, 벡터 데이터베이스, 에이전트 등을 통해 각 컴포넌트를 필요에 따라 조합할 수 있어 재사용성과 확장성이 높다.
-   단순한 질문-응답을 넘어서 여러 작업을 순차적으로 실행하는 체인과 상황에 따라 행동을 결정하는 에이전트를 통해 복잡한 작업을 자동화할 수 있다.
-   다양한 언어 모델, 벡터 데이터베이스와의 통합이 가능해 데이터 소스 확장과 빠른 검색이 가능하다.

### **3\. LangChain의 주요 개념**

1.  언어 모델 (LLM)
    -   언어 모델은 주어진 입력을 바탕으로 텍스트를 생성한다.
    -   LangChain은 다양한 언어 모델과의 통합을 지원한다.
2.  프롬프트 템플릿 (Prompt Templates)
    -   프롬프트 템플릿은 프롬프트를 동적으로 생성하는 데 사용된다.
    -   특정 입력 값에 따라 템플릿이 채워져 모델에 전달되므로 반복적인 작업을 단순화한다.
3.  체인 (Chains)
    -   여러 단계를 거치는 워크플로우를 하나로 묶어주는 기능이다.
    -   사용자의 질문을 분석해 필요한 데이터를 검색하고, 검색 결과를 기반으로 응답을 생성하는 일련의 과정을 체인으로 구성할 수 있다.
4.  에이전트 (Agents)
    -   동적으로 필요한 작업을 결정하고 수행하는 컴포넌트이다.
    -   질문에 따라 답변하기 위해 API 호출이 필요한지, 또는 단순히 텍스트 생성을 해야 하는지를 판단해 작업을 실행한다.
5.  벡터 데이터베이스 (Vector Databases)
    -   벡터 데이터베이스는 텍스트를 벡터로 변환해 저장하고, 이후 유사한 벡터를 빠르게 검색할 수 있도록 돕는다.
    -   이를 통해, 저장된 데이터와 유사한 질문에 빠르게 응답할 수 있다.