오늘은 알고리즘 코드카타와 LLM & RAG를 활용한 AI 서비스 만들기 1~2주차를 수강하였다.

### **LLM**

---

### **1\. 개념**

-   Large Language Model의 약자로 대규모 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 AI 모델이다.
-   기본적으로 자연어 처리(NLP)의 다양한 작업을 할 수 있다.
-   수십억 개의 파라미터를 기반으로 한 인공지능이며, 이를 통해, 마치 사람처럼 문맥을 파악하고 자연스럽게 대답할 수 있는 능력을 가진다.

### 2\. 동작원리

1.  학습 텍스트
    -   대규모 데이터 셋을 이용해 학습한다.
    -   수많은 텍스트에서 단어와 문장의 패턴을 찾아내어, 새로운 문장이나 답변을 생성할 때 그 패턴을 적용한다.
2.  추론
    -   학습된 LLM은 사용자로부터 특정한 입력을 받으면, 그에 맞는 행동을 수행한다.
    -   사람의 말은 맥락을 이해해야 하기 떄문에 LLM은 자연스럽게 맥락을 이해할 수 있어야한다.
3.  미세 조정
    -   특정한 서비스나 최적화된 LLM을 만들기 위해 필요하다.

### 3.LLM의 랜덤성과 조건성

1.  랜덤성
    -   LLM은 기본적으로 확률에 기반한다.
    -   모델이 동작할 때마다 새로운 문장이 생성된다.
    -   랜덤성은 모델이 새로운 문장을 만들어 내는 능력을 키워주는 핵심 요소이다.
    -   LLM이 결과를 생성할 때, 토크의 확률 분포를 사용하고 그 중 가장 높은 확률을 가진 토큰을 선택해 문장을 만든다. 이 떄 온도라는 매개변수가 영향을 미친다. 온도 값이 낮으면 모델은 더 일관되고 예측 가능한 답변을 생성하고 온도 값이 높으면 창의적이고 예측하기 어려운 답변이 나올 수 있다.
2.  조건성
    -   조건부 확률을 기반으로 결과를 만들어 낸다.
    -   즉, 모델은 이전 내용에 입력에 따라 문장을 조건부로 생성하게 되는데, 이를 컨텍스터라고 한다.
    -   이 과정에서 프롬프트와 맥락 기억이 중요하다.

### **RAG**

---

### **1\. 개념**

-   Retrieval-Avgmented Generation의 약자로, 말 그대로 검색 기반 생성 기법이다.
-   LLM은 많은 데이터를 학습했음에도, 최신 정보나 특정 도메인 지식에 대한 한계를 가질 수 있다. 이를 보완하기 위해 RAG를 사용한다.
-   외부 데이터베이스나 문서에 관련 정보를 검색한 후, 그 정보를 바탕으로 답변을 생성한다.

### **2\. 동작 원리**

-   사용자가 입력을 주면, RAG 시스템은 답변을 생성하기 전에 검색 단계를 거친다.
-   벡터 DB나 키타 정보 저장소에서 질문과 관련된 문서를 검색한다. 이 때 사용되는 검색 방법은 텍스트를 벡터화하여 의미적으로 유사한 문서를 찾는 것이다.
-   검색된 문서를 바탕으로 최종적으로 답변을 생성한다.

### **3\. 장점**

-   최신 데이터베이스에서 정보 검색이 가능하다.
-   도메인 특화된 정보 제공이 가능하여, 일반적인 LLM보다 더 정확한 정보를 제공한다.
-   필요 정보만 검색해오기 때문에 다른 시스템보다 빠르다.

### **4\. 단점**

-   외부 데이터 소스에서 정보를 가져오기 때문에, 이 정보의 정확성이나 신뢰성이 떨어질 수 있고 잘못된 정보가 포함될 수도 있다.
-   다양한 문서에서 정보를 검색하기 때문에, 생성된 응답이 일관되지 않거나 모순될 수 있다.

### **Vector DB**

---

### **1\. 개념**

-    숫자의 나열인 벡터를 저장하고, 그 벡터를 기반으로 데이터를 빠르고 효율적으로 검색하는 데이터베이스이다.
-   벡터 DB는 임베딩이라는 방법으로 데이터를 벡터화하여, 유사한 의미를 가진 데이터들을 빠르게 검색할 수 있게 해준다.
-   임베딩은 텍스트나 이미지를 숫자의 나열인 벡터로 변환하는 과정이다.

### **2.동작과정**

-   문서나 텍스트를 벡터로 변환한다.
-   생성된 벡터는 벡터 데이터 베이스에 저장한다.
-   사용자가 검색어나 명령을 입력하면, 그 명령이나 검색어를 벡터로 변환한 후, 벡터 데이터베이스에서 유사한 벡터를 찾아낸다.
-   유사한 벡터를 가진 문서나 데이터를 다시 문장 형태로 바꾸어 결과를 제공한다.

### **3\. 장점**

-   문장을 검색할 때 단순히 키워드를 매칭하는 것이 아니라, 의미 단위로 검색이 가능하여, 유사한 의미를 가진 텍스트도 검색이 가능하다.
-   대량의 벡터 데이터를 빨리 처리 할 수 있고, 대규모 텍스트 데이터에 대해 효율적인 검색을 할 수 있다.

### **4\. 단점**

-   일반적인 관계형 데이터베이스보다 구조가 복잡하고, 벡터 임베딩 생성 및 관리에 대한 이해가 필요하다.
-   고차원 벡터를 저장하기 때문에, 많은 양의 데이터를 저장할 경우 메모리 사용량이 상당히 증가할 수 있다.
-   벡터를 주기적으로 업데이트해야 하는 경우, 기존 벡터와 일관성을 유지하는 것이 어려울 수 있다.

### **LangChain**

---

### **1\. 개념**

-   LLM과 같은 언어 모델을 더욱 효율적으로 활용할 수 있게 도와주는 프레임워크이다.
-   LLM의 기능을 더욱 확장하고, 데이터 소스, API, DB등 쉽게 통합 할 수 있다.

### **2\. 동작 원리**

-   여러 단계의 프롬프트를 연속적으로 연결하여 복잡한 작업을 수행할 수 있다.
-   메모리 기능을 통해 대화의 맥락을 유지할 수 있게 해준다.
-   API, DB, 웹 검색 등 다양한 외부 리소스를 결합해 LLM의 한계를 보완할 수 있다.

### **3\. 장점**

-   복잡한 언어 작업을 자동화하거나 여러 단게의 작업을 간단히 연결할 수 있다.
-   강력한 AI 시스템을 구축할 수 있다.
-   챗봇이나 고급 대화 시스템을 만드는데 유리하다.

### **4\. 단점**

-   다양한 구성 요소와 기능을 포함하고 있어, 처음 사용하는 사용자에게는 학습 곡선이 가파를 수 있다.
-   여러 외부 라이브러리와 API에 의존하기 때문에, 이들 중 하나가 변경되거나 중단되면 전체 시스템에 영향을 미칠 수 있다.
-   특정 프레임워크나 라이브러리에 의존하므로, 사용자 정의 기능이나 요구사항을 구현하는 데 제약이 있을 수 있다.

### **OpenAI Playground**

---

### **1\. 개념**

-   OpenAI에서 제공하는 웹 기반의 실험 환경이다.
-   프롬프트를 입력해 보고, 그에 대한 응답을 실시간 확인이 가능하다.
-   다양한 파라미터 설정을 통해 모델의 동작을 제어한다.

### **2.할 수 있는 것**

-   사용자가 입력한 프롬프트를 바탕으로 GPT모델이 답변을 생성한다.
-   단순한 대화뿐만 아니라 긴 텍스트를 요약하거나, 텍스트를 다른 언어로 번역하거나, 주어진 텍스트에서 질문에 답변을 생성하거나, 창의적인 텍스트 작성이 가능하다.
-   프롬프트 작성의 방식이나 내용에 따라 모델의 응답이 어떻게 달라지는지 실험할 수 있다.

### **3\. 주요 설정**

1.  모델 선택
    -   GPT-4 family는 최신이자 가장 강력한 언어 모델로, 복잡한 작업과 창의적인 응답이 필요할 떄 사용한다.
    -   GPT-3.5 family는 조금 더 가벼운 버전으로, 빠르고 효율적인 응답을 생성한다.
2.  온도
    -   값이 높을수록 창의적이고 예측 불가능한 응답이 나오고, 낮을수록 일관적이고 안정적인 응답이 나온다.
    -   0.0은 완전히 고정된 응답이고 1.0은 매우 창의적이고 다채로운 응답이다.
3.  토큰 길이
    -   토큰은 GPT 모델에서 사용하는 단위로, 생성할 수 있는 텍스트의 길이를 조절하는 값이다.
    -   기본적으로 짧은 응답을 원하면 낮은 값을, 긴 응답을 원하면 높은 값을 설정한다.
4.  탑-피
    -   응답의 다양성을 제어하는 또 다른 파라미터이다.
    -   1.0은 모든 가능한 답변을 고려해 다양한 응답을 생성하고 0.5는 확률 상위 50%에 해당하는 답변들만 선택하여, 더 집중된 응답을 생성한다.
5.  프롬프트 형식
    -   프롬프트 종료를 위한 특정 단어나 기호를 설정해, 응답이 해당 기호에 도달하면 멈추도록 할 수 있다.

### **4\. 주의할 점**

-   Frequency Penalty는 이미 사용한 단어나 문장을 반복하지 않도록 하는 설정으로, 값을 높이면 중복된 표현을 줄이게 된다.
-   Presence Penalty는 새로운 단어나 아이디어를 더 많이 사용하도록 유도하는 설정으로, 값을 높이면 더 다양한 표현이 나온다.

### **프롬프트 엔지니어링**

---

### **1\. 개념**

-   인공지능 모델, 특히 LLM에 적절한 입력을 설계하고 작성하여, 모델이 최적의 응답을 하도록 유도하는 기술이다.
-   프롬프트가 잘 설계되면 정확하고 유용한 결과를 얻을 수 있고, 반대로 잘못된 프롬프트는 부정확한 답변이나 혼란스러운 결과를 초래한다.
-   프롬프트의 구조나 어조를 조정해, 답변의 품질과 일관성을 높이는 것이 중요하다.

### **2.동작원리**

-   사용자가 모델에 질문이나 요청을 입력한다.
-   LLM은 입력된 프롬프트를 기반으로 맥락을 분석하고, 그에 맞는 적절한 답변을 생성한다.
-   학습된 데이터를 기반으로 각 단어나 문장의 확률 분포를 계산해, 가장 가능성 높은 답변을 선택한다.

### **3.System, Assistant, User**

1.  User(사용자)
    -   User는 모델과 대화하는 주체로, 질문이나 요구사항을 전달하는 역할이다.
    -   명확한 요청을 포함할수록 명확한 응답이 나오므로 최대한 구체적이고 상세한 요청을 하는 것이 좋다.
    -   요청이나 명령을 하다보니, 명령문 혹은 질문 형태의 프롬프트가 많다.
2.  Assitant(도우미)
    -   User의 질문에 답변을 제공하는 역할로, 실제 GPT 모델이 수행하는 부분이다.
    -   User의 입력에 따라 적절한 답변을 생성해내는 것이 역할이다.
    -   구현적으로 봤을 때는 이전 대화를 저장하고 연속성을 유지하기 위해 사용될 수도 있다.
3.  System(시스템)
    -   대화의 기본 규칙과 Assistant의 성격을 결정한다.
    -   대화의 배경과 규칙을 설정해, 모델이 답변을 생성할 때 어떤 스타일과 어조를 사용할지 지시할 수 있다.
    -   모델이 특정한 태도나 전문성을 갖고 응답하도록 프레임워크를 제공한다.

### **4\. 주의할 점**

-   모델이 혼란을 겪지 않도록, 프롬프트는 구체적이고 명확하게 작성해야 한다.
-   LLM은 이전 대화 내용을 기반으로 답변하므로, 맥락을 유지하는 것이 중요하다. 만약 요청한 사항과 뒤에 요청한 사항이 다르다면 점점 다른 답만 나오게 된다.
-   System 프롬프트는 Assistant의 응답 스타일과 태도에 큰 영향을 미치므로, 올바르게 System 프롬프트를 설정하여 대화의 질을 높이고, 사용자가 원하는 특정 답변 스타일을 확보한다.