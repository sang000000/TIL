오늘은 딥러닝 5주차를 수강하였고 알고리즘 코드카타와 과제를 풀어보았다.

### **오토인코더**

---

### **1\. 개념**

-   입력 데이터를 압축하고, 이를 다시 복원하는 과정을 통해 데이터를 효율적으로 표현하는 비지도 학습 모델이다.
-   주로 차원 축소, 잡음 제거, 생성 모델 등 다양한 분야에서 활용한다.

### **2\. 동작 원리**

1.  인코더(Encoder)
    -   높은 차원의 입력 데이터를 저차원 표현으로 변환하는 역할이다.
    -   인코더의 목적은 주용한 특징을 추출하고, 입력 데이터를 압축하는 것이다.
2.  디코더(Decoder)
    -   인코더에 의해 생성된 저차원 표현을 다시 원래의 고차원으로 복원하는 역할이다/
    -   디코더에 목적은 입력 데이터를 최대한 원본과 가깝게 복원 하는 것이다.
    -   적은 데이터를 보고 원본의 데이터를 생성하는데 학습하게 된다.
3.  잠재 공간(Latent Space)
    -   인코더에 의해 생성된 저차원 표현 공간이다.
    -   이 공간에서는 입력 데이터의 중요한 특징만을 포함하고 있으며, 디코더는 이를 이용해 원래 데이터를 복원한다.

### **3\. 오토인코더 구조**

1.  기본 오토인코더
    -   기본적으로 인코더 → 잠재 공간 → 디코더 형태로 구성된다.
2.  변형된 오토인코더
    -   딥 오토인코더
        -   더 깊은 인코더와 디코더 구조를 가지며, 더 복잡한 구조를 학습이 가능하다.
        -   여러 층을 통해 데이터를 계층적으로 추출할 수 있다.
    -   변분 오토인코더
        -   데이터의 잠재 공간을 평균과 분산으로 표현하여 데이터의 분포를 학습한다.
    -   회소 오토인코더
        -   일부러 출력이 희소하게 제약을 두어서 출력 값 중 많은 수가 0이 되도록 하는 걸 목표로 둔다.
        -   데이터의 중요한 특징을 명확하게 추출하기 때문에 차원의 저주를 조금 완화한다.
    -   잡음 제거 오토 인코더
        -   입력 데이터에 인위적으로 잡음을 추가하고, 이 잡음을 알아서 제거하는 학습을 통해 데이터를 복원하는 방식으로 학습한다.
        -   데이터에 굉장히 강력한 모델이 학습된다.
        -   손상된 데이터나 잡음이 있는 데이터를 효과적으로 복원이 가능하다.

### **GAN**

---

### **1\. 개념**

-    두개의 신경망, 즉 생성자와 판별자로 구성되어 있다.
-   생성자는 가짜 데이터를 생성하고, 판별자는 이 데이터가 진짜인지 가짜인지 판별하며, 서로 경쟁하여 동시에 학습한다.

### **2\. 동작 원리**

1.  생성자
    -   랜덤 노이즈 벡터를 입력으로 받아서 이를 통해 가짜 데이터를 생성한다.
    -   생성된 데이터는 판별자에게 전달되어 진짜 데이터처럼 보이도록 학습한다.
2.  판별자
    -   진짜 데이터와 생성된 가짜 데이터를 입력 받아 이를 구분한다.
    -   판별자는 진짜 데이터는 1로, 가짜 데이터는 0으로 분류되도록 한다.
3.  경쟁 과정
    -   생성자는 판별자를 속이기 위해 점점 더 진짜 같은 데이터를 생성하려고 노력한다.
    -   판별자는 생성자가 만든 가짜 데이터를 더 잘 구분하려고 노력한다.
    -   이 과정에서 두 네트워크는 서로 경쟁하며 동시에 발전한다.

### **3\. 장점**

-   고품질의 데이터를 생성한다.
-   다양한 작업에 적용될 수 있는 구조를 가진다.

### **4\. 단점**

-   훈련이 굉장히 불안정하다.
-   두 네트워크의 경쟁이 조율되지 않으면, 둘 다 학습이 안된다.
-   생성자가 데이터를 제한된 형태로만 생성하는 문제가 일어날 수 있다.

### **VAE**

---

### **1\. 개념**

-   인코더와 디코더로 구성된 오토인코더의 변형이다.
-   인코더는 입력 데이터를 잠재 공간으로 매핑하고, 디코더는 이 잠재 공간에서 데이터를 원래 공간으로 복원한다.
-   잠재 공간을 확률 분포로 모델링하여, 새로운 데이터 생성과 데이터의 분포를 효과적으로 학습한다.

### **2\. 응용**

-   새로운 이미지를 생성하는데 사용한다.
-   잠재 공간으로 압축하고, 이를 통해 데이터 압축 및 복원에 사용 가능하다.
-   노이즈가 있는 데이터를 입력으로 받아서 노이즈를 제거한 깨끗한 데이터를 출력할 수 있다.

### **전이 학습**

---

### **1\. 개념**

-   이미 학습된 모델의 지식을 새로운 문제에 적용하는 방법이다.
-   특히 데이터가 부족한 상황에서 유용하며, 모델의 학습 시간을 단축하고 성능을 향상할 수 있다.

### **2\. 필요성**

-   새로운 문제에 대한 데이터가 충분하지 않을 때, 전이 학습을 통해 기존 모델의 지식을 활용이 가능하다.
-   사전 학습된 모델을 사용시, 처음부터 모델을 학습하는 것보다 빠르게 학습이 가능하다.
-   사전 학습된 모델은 대규모 데이터 셋에서 학습되었기 떄문에, 통상 더 나은 성능을 보인다.

### **3\. 원리**

-   특징 추출기: 사전 학습된 모델의 초기 층을 고정하고, 새로운 데이터에 맞게 마지막층(결정하는 층)만 재학습한다.
-   미세 조정: 사전 학습된 모델 전체를 새로운 데이터에 맞게 가중치를 바꾼다.

### **4\. 전이 학습을 적용한 모델 구축 과정**

1.  사전 학습된 모델 로드
    -   PyTorch에서 제공하는 사전 학습된 모델을 로드한다.
2.  모델 수정
    -   사전 학습된 모델의 마지막 층은 새로운 문제에 맞게 수정한다.
3.  모델 학습
    -   수정된 모델을 새로운 데이터에 맞게 학습한다.
