오늘은 알고리즘 코드카타와 AI 모델의 활용 3~4주차 강의를 수강하였다.

벌써 한달이 되었다 시간이 참 빨리 지나가는 것 같다.

### **Transformers 라이브러리**

---

### **1\. 개념**

-   다양한 NLP모델을 쉽게 사용할 수 있도록 도와주는 Hugging Face의 오픈 소스 라이브러리이다.
-   최신 NLP 모델들을 불러와 텍스트 생성, 감정 분석, 번역 등 다양한 작업에 활용 가능하다.

### **2\. 다양한 NLP 모델**

1.  GPT-2  
    -   openAI에서 개발한 언어 생성 모델로, 문장을 생성하거나 이어지는 텍스트를 에측하는데 뛰어난 성능을 발휘한다.
    -   Transformer 라이브러리에서 바로 사용이 가능하다.
2.  간단한 감성어 분석
    -   텍스트 데이터를 입력 받아, 그 텍스트의 감정을 분석하는 작업을 실행한다.
    -   텍스트가 긍정, 부정, 중립인지 판단에 사용한다.
3.  ROBERTA(Robustly Optimized BERT Approach)
    -   BERT 모델을 최적화한 모델 버전으로, 더 많은 데이터와 더 긴 학습 시간을 통해 성능을 향상하고, 텍스트 분류와 같은 작업에 유용하다.
    -   학습 시간을 통해 성능 향상, 텍스트 분류와 같은 직업에 유용하다.

### **사전 학습**

---

### **1\. 개념**

-   대규모의 텍스트 데이터 셋을 사용해 모델이 일반적인 언어 이해 능력을 학습하는 과정이다.
-   특정 작업을 염두에 두지 않고, 단순히 언어의 패턴과 구조를 학습하는 것이 목적이다.

### **2\. 특징**

-   방대한 양의 텍스트 데이터로 모델을 학습시킨다.
-   모델은 텍스트 내 단어의 의미, 문장 구조, 문맥 등 언어의 전반적인 특징을 학습한다.
-   특정 작업에 맞춰진 학습이 아닌, 전반적인 언어 이해에 초점을 맞춘다.

### **3\. 목적**

-   다양한 텍스트에서 기본적인 규칙을 배우고, 이후에 특정 작업에 빠르게 적응할 수 있는 기반을 다진다.

### **파인 튜닝**

---

### **1\. 개념**

-   사전 학습 된 모델을 특정 작업에 맞게 추가로 학습 시키는 과정이다.

### **2\. 특징**

-   특정 작업에 맞춰 모델을 최적화한다.
-   사전 학습된 모델의 언어 이해 능력을 바탕으로, 새로운 작업에 적응할 수 있도록 일부 가중치만 조정한다.
-   사전 학습 덕분에, 파인 튜닝은 비교적 적은 양의 데이터로도 효과적인 학습이 가능하다.

### **생성형 AI**

---

### **1\. 개념**

-   최근 AI 분야에서 큰 주목을 받고 있는 기술로, 텍스트 생성, 이미지 생성 등 다양한 창의적인 작업을 수행이 가능하다.
-   주어진 입력에 따라 새로운 콘텐츠를 생성하는 인공지능 기술이다.

### **2.종류**

-   텍스트 생성: GPT-3, chat GPT 등은 주어진 텍스트를 기반으로 자연스러운 대화나 글을 생성한다.
-   이미지 생성: DALL-E, Stable Diffusion 등은 사용자로부터 적당한 명렁어를 받아 명령어에 해당하는 이미지를 생성 가능하다.
-   음악 생성: 사용자로부터 받은 멜로디, 텍스트로부터 음성 파일을 생성이 가능하다.

### **3\. 생성형 AI를 직접 만드는 것의 어려움**

-   생성형 AI를 학습시키기 위해서는 수백만 개의 고품질 데이터가 필요하다.
-   데이터에 좋지 않거나 윤리적으로 문제가 있는 데이터가 포함되는 경우 결과물에도 반영이 될 수 있다.
-   GPU 또는 TPU와 같은 고성능 하드웨어에서 오랜 시간 핛브을 해야하기 때문에 개인이 하기 어려우며, 클라우드 서비스를 사용하여도 비용이 상당하다.
-   여러 층의 신경망과 다양한 메커니즘을 포함하고 있어, 올바른 설계가 매우 어렵다.
-   다양한 하이퍼파라미터를 적절히 조절해야 최적의 성능을 낼 수 있어 많은 실험과 경험이 필요하다.
-   훈련 중에 무작위하게 출력이 고정되거나 의미없느 결과를 생성하는 모델 붕괴 현상을 겪을 수 있다/
-   고품질의 출력을 생성하기 위해서는 학습 데이터를 적절히 사용하고, 학습 과정에서 다양한 출력을 생성하도록 모델을 조절한다.

### **4\. 파인 튜닝의 필요성**

-   사전 학습된 모델을 특정 작업에 맞게 추가로 학습시키므로 생성형 AI 모델을 보다 쉽게 적용 가능하다.
-   이미 일반적인 언어 패턴을 학습한  상태이므로, 적은 데이터와 자원으로도 높은 성능을 얻을 수 있다.

### **5\. 생성형 AI 제작 시 고려 사항**

-    생성형 AI로 인종차별적인 언어를 생성하거나 범죄에 이용하지 못하게 충분히 고려해야 한다.
-   사전 학습된 모델을 먼저 찾아서 사용하는 것이 효율적이다.
-   강력한 컴퓨팅 자원이 필요하다면, 클라우드 서비스를 활용하여 시간을 감소하고 메모리적인 부분 땜에 억지로 학습을 축소하는 경우를 예방한다.
-   작은 프로젝트부터 시작해서 천천히 확장해 나가면서 이해를 높이고 점진적으로 복잡한 모델을 만드는 것이 좋다.

### **생성형 모델의 기본 원리**

---

### **1\. 랜덤성**

-   랜덤성은 다양한 결과를 생성할 수 있도록 도와주는 중요한 요소이다.
-   일정한 확률에 따라 다양한 선택지를 고려하게 한다. 이로 인해 생성된 데이터는 매번 조금씩 다르게 생성 될 수 있다.
-   생성형 모델은 학습 데이터를 통해 얻은 확률 분포를 기반으로 새로운 데이터를 생성한다.

### **2\. 조건성**

-   조건성은 특정 조건을 기반으로 데이터를 생성하는 능력이다.
-   생성형 모델은 입력된 조건에 따라 결과를 다르게 생성한다.
-   조건성 덕분에 매우 다양한 상황에 적용이 가능하다.

### **3\. 텍스트 기반 생성형 모델의 작동 원리**

-   사용자가 입력한 텍스트를 토큰(단어 또는 서브 워드)으로 변환한다.
-   모델은 주어진 텍스트를 기반으로 다음에 올 단어의 확률을 예측한다.
-   예측된 확률 분포에서 랜덤하게 다음 단어를 선택하고 이 때 temperature 파라미터를 조정하여 랜덤성을 조절한다.
-   이러한 과정을 반복하여 문장이 완성될 떄까지 생성한다.

### **4\. 이미지 기반 생성형 모델의 작동 원리**

-   입력된 텍스트 조건을 벡터로 인코딩하여 모델에 입력한다.
-   모델은 인코딩된 텍스트와 함께 이미지의 주요 특징을 생성한다.
-   랜덤성을 적용하여 세부적인 이미지 요소를 생성하고, 이를 합성하여 최종 이미지를 생성한다.

### **5\. 오디오 기반 생성형 모델의 작동 원리**

-   입력된 텍스트나 멜로디를 인코딩하여 모델에 입력한다.
-   모델은 인코딩된 입력을 바탕으로 오디오 신호를 생성하고, 이 과정에서 음색, 리듬, 멜로디 등을 조합한다.
-   랜덤성을 통해 음성의 미세한 변화를 추가하여, 동일한 조건에서도 다양한 오디오를 생성할 수 있다.