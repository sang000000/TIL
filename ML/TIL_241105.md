오늘은 알고리즘 코드카타 문제와 AI 모델 활용 5주차 강의 실습을 진행하였다. 결국 무료 트라이얼이 이제는 사라져, 결제를 하는 방법 이외에는 OpenAI API를 사용할 수 가 없어 5달러를 지불했다. ~거의 만원이네 ㄷㄷ 아까운 내 돈~

### **실습 코드**

---

### **1\. ChatGPT API를 사용한 환영 인사**

from openai import OpenAI

  

client \= OpenAI()

  

completion \= client.chat.completions.create(

  model\="gpt-4o",

  messages\=\[

    {"role": "system", "content": "너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘"},

    {"role": "user", "content": "안녕?"}  

  \]

)

  

print("Assistant: " + completion.choices\[0\].message.content)

-   openai 라이브러리에서 OpenAI 클래스를 임포트한다.
-   client라는 변수에 OpenAI()를 호출하여 클라이언트 객체를 생성하고 이 객체를 사용해 API 요청을 보낸다.
-   chat.completions.create() 메서드를 호출하여 챗봇의 응답을 생성하는 요청을 보낸다.
-   model 옵션에 사용할 모델의 이름을 적는다.
-   messages 옵션 부분에 {"role": "system", "content": "너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘"}는 시스템 역할을 하며, 챗봇이 어떤 역할을 해야 하는지를 정의한다.
-   {"role": "user", "content": "안녕?"} 부분은 사용자가 입력한 내용으로, 챗봇이 대답해야 할 질문을 정의한다.
-   출력문을 통해 completion 객체에서 첫번째 응답을 선택하여. message.content를 이용하여 선택한 응답의 내용을 가져와 출력한다.

### **2\. 법률 상담 대화 버전 프로그램**

from openai import OpenAI

  

client \= OpenAI()

  

system\_message \=  {

  "role": "system", "content": "너는 변호사야 나에게 법률적인 상담을 해줘. 그리고 주의사항은 말하지마. 한국법을 기준으로 "

  }

  

messages \= \[system\_message\]

  

while True :

    user\_input \= input("사용자 전달:")

    if user\_input \== "exit":

        print("대답:  즐거운 대화였습니다! 감사합니다!")

        break

  

    messages.append({"role" : "user" , "content" : user\_input })

    completion \= client.chat.completions.create(

        messages \= messages

    )

  

    reply \= completion.choices\[0\].message.content

    print("대답:  " + reply)

    messages.append({"role" : "assistant" , "content" : reply })

-   openai 라이브러리에서 OpenAI 클래스를 임포트한다.
-   client라는 변수에 OpenAI()를 호출하여 클라이언트 객체를 생성하고 이 객체를 사용해 API 요청을 보낸다.
-    system\_message 변수에 시스템 메시지를 정의하고 챗봇의 역할을 설정한다. "role": "system" 이 부분이 시스템 메시지로 설정하는 부분이고 "content": "너는 변호사야 나에게 법률적인 상담을 해줘. 그리고 주의사항은 말하지마. 한국법을 기준으로 "  이 부분이 챗봇이 어떤 역할을 할지 정하는 부분이다.
-   messages 리스트에 system\_message를 포함시켜서 초기화 시킨다.
-   while True를 실행하여 무한 반복을 시킨다.
-   반복문 안에서는 input 함수를 이용하여 사용자 입력을 받고 그걸 user\_input에 저장한다.
-   만약 user\_input이 "exit"이면 출력문을 실행하고 반복문을 종료한다.
-   exit가 아니라면 조건문을 무시하고 message 리스트에 사용자가 입력한 내용을 추가한다.
-   chat.completions.create() 메소드를 호출하여 현재까지의 대화 내용을 포함한 messages 리스트를 전달하는 거지?
-   그 후 reply에 completion 객체에서 첫번째 응답을 선택하여. message.content를 이용하여 선택한 응답의 내용을 가져와 저장한다.
-   출력문을 이용하여 reply를 출력해 챗봇의 응답을 출력한다.
-   그 후 챗봇의 응답을 message 리스트에 추가한다. "role"를 "assistant"로 설정해야 다음 대화에서 대화 맥락이 유지된다.

### **3\. ElevenLabs API를 사용한 음성 합성**

import os

import requests

from pydub import AudioSegment

from pydub.playback import play

import io

  

\# 설정 가능한 변수

output\_filename \= "output\_audio.mp3"

  

url \= "모델 URL"

headers \= {

    "xi-api-key": "API - KEY",

    "Content-Type": "application/json"

}

  

\# 문장을 입력받습니다.

text \= input("텍스트를 입력하세요: ")

  

\# 음성 생성 요청을 보냅니다.

data \= {

    "text": text,

    "model\_id": "eleven\_multilingual\_v2",

    "voice\_settings": {

        "stability": 0.3,

        "similarity\_boost": 1,

        "style": 1,

        "use\_speaker\_boost": True

    }

}

  

response \= requests.post(url, json\=data, headers\=headers, stream\=True)

  

if response.status\_code \== 200:

    audio\_content \= b""

    for chunk in response.iter\_content(chunk\_size\=1024):

        if chunk:

            audio\_content += chunk

  

    segment \= AudioSegment.from\_mp3(io.BytesIO(audio\_content))

    segment.export(output\_filename, format\="mp3")

    print(f"Success! Wrote audio to {output\_filename}")

  

    \# 오디오를 재생합니다.

    play(segment)

else:

    print(f"Failed to save file: {response.status\_code}")

-   필요한 라이브러리들을 임포트한다.
-   output\_filename에 생성된 음성 파일을 저장한다. "output\_audio.mp3" 이 부분은 음성 생성 API를 통해 생성된 음성을 저장하기 위한 파일 이름을 적는다.
-   url이라는 변수에는 음성 생성 API의 엔드포인트 URL을 저장한다.
-   headers에는 API 요청에 필요한 헤더를 설정한다. "xi-api-key" 부분에는 인증을 위해 API 키를 입력하고 "Content-Type"에는 요청의 데이터 형식을 application/json으로 설정한다.
-   text에는 input 함수를 사용하여 사용자가 음성으로 변환하고자 하는 텍스트를 입력받는다.
-   data에는 API에 전송할 데이터 구조를 설정한다. "text" 부분에는 사용자가 입력한 테스트를 설정하고 "model\_id" 부분에는 사용할 음성 생성 모델의 ID를 적고 "voice\_settings" 부분에는 "stability"로 음성의 안정성을 조절하고 "similarity\_boost"로 음성의 유사성을 높이고 "style"에는 음성의 스타일을 설정하고 "use\_speaker\_boost"에는 특정 화자를 강조한다.
-   response에는 requests.post()을 사용하고 json=data 옵션을 사용해 요청 본문에 JSON 형식으로 데이터를 포함시키고 headers=headers 옵션을 사용해 요청 헤더를 설정하고 stream=True 옵션을 사용해 응답을 스트리밍 방식으로 받을 수 있게 하여 설정한 URL에 POST 요청을 보낸다.
-   만약 response.status\_code == 200이라면, 즉 API 요청이 성공했다면 audio\_content에 수신한 음성 데이터를 바이트로 저장한다.
-   그 다음에 반복문을 통해 response.iter\_content(chunk\_size=1024)을 사용하여 응답 데이터를 1024 바이트씩 청크 단위로 읽어 chunk에 저장한다.
-   반복문 안에서는 만약 읽어온 청크가 있다면 audio\_content에 추가한다.
-   반복문이 종료되면 segment에 AudioSegment.from\_mp3()를 사용하여 수신한 바이트 데이터를 MP3 형식으로 읽어와 저장한다.
-   그후 export()를 사용하여 생성된 AudioSegment 객체를 지정한 파일 이름으로 MP3 형식으로 저장한다.
-   그 다음에 출력문을 통해 파일이 성공적으로 저장되었다는 메시지를 출력한다.
-   저장까지 끝났다면 play()를 사용해 생성된 오디오를 재생한다.
-   혹시 요청이 실패했다면 출력문을 통해 실패한 코드와 함께 오류 메시지를 출력한다.