오늘은 알고리즘 코드카타 문제와 AI 모델 활용 5주차 강의 실습을 진행하였다.

### **실습 코드**

---

### **1\. YOLOv8 모델을 사용한 객체 탐지**

from ultralytics import YOLO

import cv2

from matplotlib import pyplot as plt

  

\# YOLOv8 모델 로드 (YOLOv8s)

model \= YOLO('yolov8n.pt')  #

  

\# 이미지 파일 경로

image\_path \= 'cat.jpg'

  

\# 이미지를 모델에 입력하여 객체 탐지 수행

results \= model(image\_path)

  

\# 탐지 결과 출력

result \= results\[0\]

  

\# 탐지된 객체들이 표시된 이미지를 가져옴

img\_with\_boxes \= result.plot()  \# result.plot()은 바운딩 박스가 포함된 이미지를 반환

  

\# Matplotlib을 사용하여 이미지 출력

plt.imshow(cv2.cvtColor(img\_with\_boxes, cv2.COLOR\_BGR2RGB))

plt.axis('off')

plt.show()

-   각종 필요한 라이브러리들을 가져와준다.
-   YOLOv8 모델의 가중치 파일인 yolov8n.pt를 로드하여 model이라는 객체를 만든다.
-   image\_path에 이미지 파일에 경로를 저장한다.
-   result에 지정된 이미지 파일을 모델에 입력하여 객체 탐지를 수행하고 결과를 저장한다.
-   그 후 result에서 인덱스 0번, 즉 첫 번째 결과를 가져와 다시 result에 저장한다.
-   img\_with\_boxex에 plot() 함수를 이용하여 바운딩 박스가 포횜된 이미지를 반환하여 저장한다.
-   OpenCV를 사용하여 cvtColor()을 사용해 img\_with\_boxex에 포함된 이미지를 OpenCv는 BRG 형식으로 읽기 때문에 COLOR\_BGR2RGB를 사용하여 RGB형태로 색상을 변환하여 Matplotlib에 올바르게 표시한다.
-   그 후 plt.axis('off')를 사용하여 이미지의 축을 숨기고 plt.show()를 사용해 변환된 이미지를 화면에 표시한다.  

### **2\. 사전 학습된 ResNet 모델을 사용한 이미지 분류**

from fastai.vision.all import \*  \# fastai의 vision 라이브러리 전체 사용

import matplotlib.pyplot as plt  \# 그래프를 띄우기 위해 matplotlib 임포트

  

\# 데이터셋 로드

path \= untar\_data(URLs.PETS)  \# PETS 데이터셋 다운로드 및 압축 해제

path\_imgs \= path/'images'

  

\# 이미지 파일 라벨링 함수 정의

def is\_cat(x): return x\[0\].isupper()

  

\# 데이터블록 정의

dls \= ImageDataLoaders.from\_name\_func(

    path\_imgs, get\_image\_files(path\_imgs), valid\_pct\=0.2, seed\=42,

    label\_func\=is\_cat, item\_tfms\=Resize(224))

  

\# 데이터셋 확인

dls.show\_batch(max\_n\=9, figsize\=(7, 6))

plt.show()  \# 그래프 띄우기

  

\# 학습할 모델 정의

learn \= cnn\_learner(dls, resnet34, metrics\=accuracy)

  

\# 모델 학습

learn.fine\_tune(1)  \# 1 epoch 동안 학습

  

\# 새로운 이미지에 대한 예측

img\_path \= 'path\_to\_your\_image.jpg'  \# 사용할 이미지 경로로 변경

img \= PILImage.create(img\_path)  \# 이미지 로드

pred, \_, probs \= learn.predict(img)  \# 예측 수행

  

\# 결과 출력

print(f"Prediction: {pred}, Probability: {probs.max():.4f}")

img.show()  \# 예측된 이미지 표시

-   필요한 라이브러리를 불러온다.
-   path에는 untar\_data를 사용하여 PETS 데이터 셋을 다운로드하고 압축을 해제하여 저장한다. URLs.PETS는 fastai에서 제공하는 데이터셋의 주소이다.
-   path\_images에는 path/'images'를 저장하여 다운로드한 데이터 셋의 이미지 파일 경로를 설정하여 저장한다. path는 기본 경로이다.
-   is\_cat(x)라는 함수를 만들어서 isupper()함수를 이용하여 첫글자가 대문자인지 확인하여 고양이인지 아닌지 판별한다.
-   ImageDataLoaders.from\_name\_func(path\_imgs, get\_image\_files(path\_imgs), valid\_pct\=0.2, seed\=42,label\_func\=is\_cat, item\_tfms\=Resize(224))를 사용하여 이미지 데이터 로더를 생성한다. path\_imgs는 이미지 파일이 있는 폴더 경로를 의미하고 get\_image\_files()는 해당 폴더에서 모든 이미지 파일을 가져온다는 의미이고 vaild\_pct=0.2는 전체 데이터의 20%를 검증 데이터로 사용한다는 뜻이고 seed=42는 랜덤 시드를 설정하여 데이터 분할의 재현성을 보장한다는 뜻이고 label\_func=is\_cat은 함수를 지정하여 이미지가 고양이인지 아닌지를 결정한다는 뜻이고 item\_tfms=Resize(224)는 모든 이미지를 224X224 크기로 조정한다는 뜻이다.
-   dls.show\_batch()를 사용하여 데이터 셋에서 무작위로 선택된 이미지를 시각화한다. max\_n은 최대 몇개의 이미지를 보여 줄지 정하는 것이고 figsize는 출력 이미지의 크기를 설정한다는 뜻이다.
-   learn에는 cnn\_learner를 사용하여 모델을 정의한다. dls는 앞서 정의한 데이터 로더를 사용한다는 뜻이고 resnet34는 모델 아키텍처로 ResNet34를 사용한다는 뜻이고 metrics는 모델의 성능을 평가할 지표를 정한다는 뜻이다.
-   learn.fine\_tune()를 사용하여 모델을 선택한 숫자 에폭 동안 학습한다.
-   img\_path에는 예측할 이미지 파일의 경로를 설정한다.
-   img에는 PILmage.create()를 사용하여 지정된 경로에 이미지를 로드하여 저장한다.
-   learn.predict()를 사용하여 이미지를 분류하고, 예측 결과를 pread에 저장하고 로스 값(사용하지 않음)을 \_에 저장하고 확률 분포를 probs에 저장한다.
-   출력문을 통해 예측된 클래스와 그에 대한 최대 확률을 출력한다. probs.max()는 에측 된 클래스의 확률 중 가장 높은 값을 반환한다.
-   그 후 show()를 사용하여 예측된 이미지를 화면에 표시한다.

### **3\. 실시간 객체 탐지 시스템**

from ultralytics import YOLO

import cv2

from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QWidget, QPushButton

from PyQt5.QtCore import QTimer

from PyQt5.QtGui import QImage, QPixmap

  

class VideoCaptureWidget(QWidget):

    def \_\_init\_\_(self):

        super().\_\_init\_\_()

  

        \# YOLOv8x 모델 로드 (YOLOv8x)

        self.model \= YOLO('yolov8x.pt')

  

        \# UI 설정

        self.setWindowTitle("실시간 객체 탐지")

        self.image\_label \= QLabel(self)

        self.layout \= QVBoxLayout()

        self.layout.addWidget(self.image\_label)

  

        self.start\_button \= QPushButton("Start Webcam", self)

        self.start\_button.clicked.connect(self.start\_webcam)

        self.layout.addWidget(self.start\_button)

  

        self.stop\_button \= QPushButton("Stop Webcam", self)

        self.stop\_button.clicked.connect(self.stop\_webcam)

        self.layout.addWidget(self.stop\_button)

        self.setLayout(self.layout)

  

        \# 웹캠 초기화

        self.capture \= None

        self.timer \= QTimer(self)

        self.timer.timeout.connect(self.update\_frame)

  

    def start\_webcam(self):

        """웹캠을 시작하고, 타이머를 시작하여 프레임을 주기적으로 읽음"""

        self.capture \= cv2.VideoCapture(0)  \# 웹캠 장치 열기

        self.timer.start(20)  \# 20ms마다 프레임 업데이트 (50fps)

  

    def stop\_webcam(self):

        """웹캠을 중지하고 타이머를 멈춤"""

        self.timer.stop()

        if self.capture is not None:

            self.capture.release()

  

    def update\_frame(self):

        """웹캠에서 프레임을 읽어와서 YOLO 객체 탐지를 수행한 후 UI에 표시"""

        ret, frame \= self.capture.read()

        if ret:

            \# YOLOv8 객체 탐지 수행

            results \= self.model(frame)

            result \= results\[0\]

  

            \# 바운딩 박스가 포함된 이미지를 가져옴

            img\_with\_boxes \= result.plot()

  

            \# OpenCV 이미지를 QImage로 변환

            rgb\_image \= cv2.cvtColor(img\_with\_boxes, cv2.COLOR\_BGR2RGB)

            h, w, ch \= rgb\_image.shape

            bytes\_per\_line \= ch \* w

            convert\_to\_Qt\_format \= QImage(rgb\_image.data, w, h, bytes\_per\_line, QImage.Format\_RGB888)

  

            \# QImage를 QLabel에 표시하기 위해 QPixmap으로 변환

            self.image\_label.setPixmap(QPixmap.fromImage(convert\_to\_Qt\_format))

  

    def closeEvent(self, event):

        """윈도우 닫을 때 웹캠 해제"""

        if self.capture is not None:

            self.capture.release()

  

if \_\_name\_\_ \== "\_\_main\_\_":

    app \= QApplication(\[\])

    window \= VideoCaptureWidget()

    window.show()

    app.exec\_()

-   필요한 라이브러리를 가져온다.
-   Qwidget을 상속 받아 비디오 캡처 및 객체 탐지를 위한 VideoCaptureWidget 클래스를 정의한다.
-   super().\_\_init\_\_()을 사용하여 부모 클래스인 Qwidget을 초기화한다.
-   객체 탐지를 하기 위해 self.model = YOLO('yolov8x.pt')를 사용하여 YOLOv8 모델의 가중치를 불러온다.
-   self.setWindowTitle()를 사용하여 창의 제목을설정한다.
-   self.image\_label에 웹캠에서 캡처한 이미지를 표시할 QLabel을 생성합니다.
-   self.layout에 QVBoxLayout()를 사용하여 수직 레이아웃을 생성하여 위젯을 쌓아 올려 저장한다.
-   self.start\_button에 QPushButton()를 사용하여 웹캠을 시작하는 버튼을 생성하여 저장한다.
-   clicked.connect(self.start\_webcam)를 사용하여 버튼 클릭 시 start\_webcam 메서드를 호출하도록 연결한다.
-   self.stop\_button에 QPushButton(): 웹캠을 중지하는 버튼을 생성하여 저장한다.
-   clicked.connect(self.stop\_webcam): 버튼 클릭 시 stop\_webcam 메서드를 호출하도록 연결한다.
-   self.setLayout()을 사용하여 레이아웃을 현재 위젯에 설정한다.
-   self.capture에 None을 저장하여 웹캡처 객체를 초기화한다.
-   self.timer에 QTimer(self)을 저장하여 타이머 객체를 생성한다.
-   timeout.connect(self.update\_frame)을 사용하여 타이머가 만료될 때 update\_frame 메서드를 호출하도록 연결한다.
-   def를 사용하여 웹캠을 시작하는 start\_webcam 메서드를 만든다.
-   함수 안에서는 cv2.VideoCapture(0)를 사용하여 기본 웹캠 장치를 열어 캡처 객체를 생성하여 self.capture에 저장한다. 0은 기본 카메라를 의미한다.
-   self.timer.start(20)를 사용하여 20ms마다 update\_frame 메서드를 호출하여 프레임을 업데이트한다.
-   def을 사용하여 웹캠을 중지하고 타이머를 멈추는 stop\_webcam 메서드를 만든다.
-   함수 안에서는 self.timer.stop()를 사용하여 타이머를 중지시키고 프레임 업데이트를 멈춘다.
-   만약 웹캡처 객체가 존재하면 self.capture.release()를 사용하여 해제한다.
-   def를 사용하여 웹캠에서 프레임을 읽고 YOLO 객체 탐지를 수행하여 이미지를 업데이트하는 update\_frame 메서드를 만든다.
-   self.capture.read()을 사용하여 웹캠에서 프레임을 읽고 ret에는 프레임이 정상적으로 읽혔는지를 저장하고, frame에는 읽은 이미지를 저장한다..
-   만약 프레임이 정상적으로 읽혔을 경우에만 다음 단계를 진행한다.
-   self.model(frame)를 사용하여 YOLO 모델을 사용해 프레임에서 객체 탐지를 수행하여 results에 저장한다..
-   result에는 첫 번째 결과를 가져온다.
-   result.plot()를 사용하여 탐지된 객체에 바운딩 박스를 그린 이미지를 생성하여 img\_with\_boxes에 저장한다.
-   cv2.cvtColor(img\_with\_boxes, cv2.COLOR\_BGR2RGB)를 사용하여 img\_with\_boxes에 포함된 이미지를 OpenCV는 이미지를 BGR 형식으로 읽기 때문에 cv2.COLOR\_BGR2RGB 옵션을 사용하여 RGB형식으로 색상을 바꿔 rgb\_image에 저장한다. 
-   h, w, ch에는 rgb\_image.shape를 사용하여 각각 변환된 이미지의 높이, 너비, 채널 수를 가져와 저장한다.
-   bytes\_per\_line에는 ch \* w를 하여 한 줄의 바이트 수를 계산해서 저장한다.
-   convert\_to\_Qt\_format에는 QImage()를 사용하여 OpenCV 이미지를 QImage 형식으로 변환하여 저장한다.
-   self.image\_label.setPixmap()를 사용하여 변환된 QImage를 QLabel에 표시한다.
-   def를 사용하여 윈도우가 닫힐 때 호출되는 closeEvent 메서드를 만든다.
-   메서드 안에서는 만약 웹캡처 객체가 존재하면 해제한다.
-   if \_\_name\_\_ == "\_\_main\_\_"를 사용하여 스크립트가 직접 실행될 때만 아래 코드를 실행한다.  
    app에는 QApplication(\[\])를 사용하여 PyQt5 애플리케이션 객체를 생성해서 저장한다.  
    window에는 VideoCaptureWidget()를 사용하여 사용자 정의 위젯을 생성해서 저장한다.  
    window.show()를 사용해 시작한다.